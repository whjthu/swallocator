[2879803 ## mn111: 25088 ## 2021-08-23/03:10:31] cnodenum= 1, job-resource-list: 103559[mpemap:0x1][spemap:0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF]
[2879803 ## mn111: 25088 ## 2021-08-23/03:10:31] control node is: mn111.
[2879803 ## mn111: 25088 ## 2021-08-23/03:10:31] sub control node number is 1, list: mn012.
vn103559: no optimizer found. set to paro
vn103559: using world size: 1, data-parallel-size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
vn103559: using torch.float32 for parameters ...
vn103559: WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:BertWordPieceLowerCase
vn103559: ------------------------ arguments ------------------------
vn103559:   adam_beta1 ...................................... 0.90000000000000002
vn103559:   adam_beta2 ...................................... 0.999
vn103559:   adam_eps ........................................ 1e-08
vn103559:   adlr_autoresume ................................. False
vn103559:   adlr_autoresume_interval ........................ 1000
vn103559:   apex_o1 ......................................... False
vn103559:   apply_query_key_layer_scaling ................... True
vn103559:   apply_residual_connection_post_layernorm ........ False
vn103559:   attention_dropout ............................... 0.10000000000000001
vn103559:   attention_softmax_in_fp32 ....................... False
vn103559:   balance_loss_weight ............................. 1
vn103559:   balance_strategy ................................ swipe
vn103559:   bert_load ....................................... None
vn103559:   bf16 ............................................ False
vn103559:   bias_dropout_fusion ............................. False
vn103559:   bias_gelu_fusion ................................ False
vn103559:   block_data_path ................................. None
vn103559:   checkpoint_activations .......................... False
vn103559:   checkpoint_num_layers ........................... 1
vn103559:   clip_grad ....................................... 1.0
vn103559:   concat_two ...................................... True
vn103559:   consumed_train_samples .......................... 0
vn103559:   consumed_valid_samples .......................... 0
vn103559:   crazy ........................................... False
vn103559:   crazy_dp ........................................ -1
vn103559:   data_impl ....................................... mmap
vn103559:   data_parallel_size .............................. 1
vn103559:   data_path ....................................... None
vn103559:   DDP_impl ........................................ local
vn103559:   distribute_checkpointed_activations ............. False
vn103559:   distributed_backend ............................. mpi
vn103559:   eod_mask_loss ................................... True
vn103559:   eval_interval ................................... 50
vn103559:   eval_iters ...................................... 10
vn103559:   exit_duration_in_mins ........................... None
vn103559:   exit_interval ................................... None
vn103559:   faiss_use_gpu ................................... False
vn103559:   finetune ........................................ False
vn103559:   fmoefy .......................................... False
vn103559:   fp16 ............................................ False
vn103559:   fp32_allreduce .................................. False
vn103559:   fp32_dynamic_loss_scale ......................... False
vn103559:   fp32_fast_linear ................................ False
vn103559:   fp32_layernorm .................................. False
vn103559:   fp32_residual_connection ........................ False
vn103559:   fp32_static_loss_scale .......................... 1.0
vn103559:   global_batch_size ............................... 12
vn103559:   half_lm_cross_entropy ........................... False
vn103559:   hidden_dropout .................................. 0.10000000000000001
vn103559:   hidden_hidden_size .............................. 6144
vn103559:   hidden_size ..................................... 6144
vn103559:   hysteresis ...................................... 2
vn103559:   ict_head_size ................................... None
vn103559:   ict_load ........................................ None
vn103559:   indexer_batch_size .............................. 128
vn103559:   indexer_log_interval ............................ 1000
vn103559:   init_method_std ................................. 0.01
vn103559:   initial_loss_scale .............................. 4294967296
vn103559:   layernorm_epsilon ............................... 1.0000000000000001e-05
vn103559:   lazy_mpu_init ................................... None
vn103559:   load ............................................ ./ckpt/m6-1231
vn103559:   local_rank ...................................... None
vn103559:   log_interval .................................... 1
vn103559:   loss_scale ...................................... None
vn103559:   loss_scale_window ............................... 1000
vn103559:   lr .............................................. 2.0000000000000002e-05
vn103559:   lr_decay_iters .................................. 1000
vn103559:   lr_decay_samples ................................ None
vn103559:   lr_decay_style .................................. linear
vn103559:   lr_warmup_fraction .............................. 0.02
vn103559:   lr_warmup_iters ................................. 0
vn103559:   lr_warmup_samples ............................... 0
vn103559:   lunatic ......................................... False
vn103559:   m6_img_feature_dim .............................. 2048
vn103559:   m6_img_file_list ................................ /home/export/online1/mdt00/shisuan/swpacai/dataset/train_100_img.flist
vn103559:   m6_patch_nums ................................... 16
vn103559:   m6_txt_file_list ................................ /home/export/online1/mdt00/shisuan/swpacai/dataset/train_100_txt.flist
vn103559:   make_vocab_size_divisible_by .................... 512
vn103559:   mask_prob ....................................... 0.14999999999999999
vn103559:   max_position_embeddings ......................... 128
vn103559:   merge_file ...................................... None
vn103559:   micro_batch_size ................................ 12
vn103559:   min_loss_scale .................................. 1.0
vn103559:   min_lr .......................................... 0.0
vn103559:   mmap_warmup ..................................... False
vn103559:   moe_size ........................................ 256
vn103559:   no_load_optim ................................... False
vn103559:   no_load_rng ..................................... False
vn103559:   no_mid_align .................................... False
vn103559:   no_save_optim ................................... False
vn103559:   no_save_rng ..................................... False
vn103559:   num_attention_heads ............................. 8
vn103559:   num_experts ..................................... 1
vn103559:   num_layers ...................................... 5
vn103559:   num_workers ..................................... 0
vn103559:   onnx_safe ....................................... None
vn103559:   openai_gelu ..................................... False
vn103559:   optimizer_type .................................. paro
vn103559:   override_lr_scheduler ........................... False
vn103559:   pad_mask_loss ................................... True
vn103559:   params_dtype .................................... torch.float32
vn103559:   pipeline_model_parallel_size .................... 1
vn103559:   print_ops ....................................... False
vn103559:   print_ops_freq .................................. -1
vn103559:   prompt_length ................................... 512
vn103559:   query_in_block_prob ............................. 0.10000000000000001
vn103559:   rampup_batch_size ............................... None
vn103559:   rank ............................................ 0
vn103559:   report_topk_accuracies .......................... []
vn103559:   reset_attention_mask ............................ False
vn103559:   reset_position_ids .............................. False
vn103559:   save ............................................ ./ckpt/m6-1231
vn103559:   save_interval ................................... 50
vn103559:   scaled_masked_softmax_fusion .................... False
vn103559:   scaled_upper_triang_masked_softmax_fusion ....... False
vn103559:   seed ............................................ 1234
vn103559:   seq_length ...................................... 128
vn103559:   share_gate ...................................... False
vn103559:   short_seq_prob .................................. 0.10000000000000001
vn103559:   sn_size ......................................... 256
vn103559:   split ........................................... 990,9,1
vn103559:   sw_align ........................................ 192
vn103559:   tensor_model_parallel_size ...................... 1
vn103559:   tensorboard_dir ................................. None
vn103559:   titles_data_path ................................ None
vn103559:   tokenizer_type .................................. BertWordPieceLowerCase
vn103559:   top_k ........................................... 2
vn103559:   train_iters ..................................... 1000
vn103559:   train_samples ................................... None
vn103559:   use_checkpoint_lr_scheduler ..................... False
vn103559:   use_cpu_initialization .......................... True
vn103559:   use_one_sent_docs ............................... False
vn103559:   vocab_file ...................................... ./dataset/vocab.txt
vn103559:   weight_decay .................................... 0.01
vn103559:   world_size ...................................... 1
vn103559:   zero_gate ....................................... False
vn103559: -------------------- end of arguments ---------------------
vn103559: setting number of micro-batches to constant 1
vn103559: > building BertWordPieceLowerCase tokenizer ...
vn103559:  > padded vocab (size: 21128) with 376 dummy tokens (new size: 21504)
vn103559: > initializing torch distributed ...
vn103559: > initializing tensor model parallel with size 1
vn103559: > initializing pipeline model parallel with size 1
vn103559: > Megatron distributed init time 0.028812885284423828 s
vn103559: > setting random seeds to 1234 ...
vn103559: time to initialize megatron (seconds): 110.230
vn103559: [after megatron is initialized] datetime: 2021-08-23 03:11:42 
vn103559: building GPT model ...
vn103559:  > number of parameters with row size 240: 2.410930e+09
vn103559: time (ms) | build model: 798.75
vn103559: [ParO] Total params 2410930176, own params 2410930176
vn103559: > learning rate decay style: linear
vn103559: Loading checkpoint from ./ckpt/m6-1231
vn103559: WARNING: could not find the metadata file ./ckpt/m6-1231/latest_checkpointed_iteration.txt 
vn103559:     will not load any checkpoints and will start from random
vn103559: time (ms) | load checkpoint: 2.74
vn103559: > building train, validation, and test datasets ...
vn103559:  > datasets target sizes (minimum size):
vn103559:     train:      12000
vn103559:     validation: 2520
vn103559:     test:       120
vn103559: > building train, validation, and test datasets for GPT ...
vn103559:     train:
vn103559:       file list indices in [0, 3) total of 3 files
vn103559:     valid:
vn103559:       file list indices in [3, 3) total of 0 files
vn103559:     test:
vn103559:       file list indices in [3, 3) total of 0 files
vn103559: > finished creating GPT datasets ...
vn103559: [after dataloaders are built] datetime: 2021-08-23 03:11:43 
vn103559: [after model, optimizer, and learning rate scheduler are built] datetime: 2021-08-23 03:11:43 
vn103559: done with setups ...
vn103559: time (ms) | model and optimizer: 1031.65 | train/valid/test data iterators: 304.91
vn103559: training ...
vn103559: [before the start of training step] datetime: 2021-08-23 03:11:43 
vn103559: forwarding 0. Mem: 17.961 GB
vn103559: backwarding 0. Mem: 21.590 GB
vn103559: optimizing. Mem: 26.941121324896812 GB
vn103559:  iteration        1/    1000 | consumed samples:           12 | elapsed time per iteration (ms): 4828.6 | total FLOPS: 0.000000e+00 | learning rate: 1.000E-06 | global batch size:    12 | lm loss: 1.020838E+01 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 21.590 GB |
vn103559: memory report func mocked
vn103559: time (ms) | forward-compute: 900.04 | backward-compute: 1390.35 | backward-embedding-all-reduce: 0.11 | optimizer: 2527.61 | paro-collect: 711.00 | optimizer-compute: 1581.00 | paro-dispatch: 235.38 | paro-row-rsm: 1.00 | paro-col-allred: 1.25 | paro-row-allg: 112.77 | batch-generator: 40.15
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        2/    1000 | consumed samples:           24 | elapsed time per iteration (ms): 4700.1 | total FLOPS: 4.765292e+12 | learning rate: 2.000E-06 | global batch size:    12 | lm loss: 1.020217E+01 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 896.18 | backward-compute: 1372.68 | backward-embedding-all-reduce: 0.11 | optimizer: 2418.60 | paro-collect: 709.77 | optimizer-compute: 1473.53 | paro-dispatch: 235.12 | paro-row-rsm: 1.01 | paro-col-allred: 1.13 | paro-row-allg: 112.50 | batch-generator: 37.86
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        3/    1000 | consumed samples:           36 | elapsed time per iteration (ms): 4705.0 | total FLOPS: 4.760362e+12 | learning rate: 3.000E-06 | global batch size:    12 | lm loss: 9.787419E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 896.65 | backward-compute: 1374.64 | backward-embedding-all-reduce: 0.16 | optimizer: 2421.56 | paro-collect: 710.35 | optimizer-compute: 1475.33 | paro-dispatch: 235.71 | paro-row-rsm: 1.00 | paro-col-allred: 1.15 | paro-row-allg: 112.96 | batch-generator: 38.31
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        4/    1000 | consumed samples:           48 | elapsed time per iteration (ms): 4716.4 | total FLOPS: 4.748917e+12 | learning rate: 4.000E-06 | global batch size:    12 | lm loss: 9.739150E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 908.68 | backward-compute: 1376.47 | backward-embedding-all-reduce: 0.11 | optimizer: 2418.34 | paro-collect: 709.19 | optimizer-compute: 1473.62 | paro-dispatch: 235.35 | paro-row-rsm: 1.00 | paro-col-allred: 1.13 | paro-row-allg: 112.79 | batch-generator: 43.01
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        5/    1000 | consumed samples:           60 | elapsed time per iteration (ms): 4705.8 | total FLOPS: 4.759568e+12 | learning rate: 5.000E-06 | global batch size:    12 | lm loss: 9.532549E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 895.72 | backward-compute: 1378.18 | backward-embedding-all-reduce: 0.11 | optimizer: 2419.86 | paro-collect: 709.11 | optimizer-compute: 1474.85 | paro-dispatch: 235.73 | paro-row-rsm: 1.01 | paro-col-allred: 1.24 | paro-row-allg: 112.89 | batch-generator: 37.40
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        6/    1000 | consumed samples:           72 | elapsed time per iteration (ms): 4713.6 | total FLOPS: 4.751707e+12 | learning rate: 6.000E-06 | global batch size:    12 | lm loss: 9.455691E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 909.65 | backward-compute: 1375.07 | backward-embedding-all-reduce: 0.11 | optimizer: 2416.24 | paro-collect: 708.42 | optimizer-compute: 1472.63 | paro-dispatch: 235.02 | paro-row-rsm: 1.01 | paro-col-allred: 1.14 | paro-row-allg: 112.49 | batch-generator: 41.32
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        7/    1000 | consumed samples:           84 | elapsed time per iteration (ms): 4717.7 | total FLOPS: 4.747609e+12 | learning rate: 7.000E-06 | global batch size:    12 | lm loss: 9.043534E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 906.42 | backward-compute: 1379.21 | backward-embedding-all-reduce: 0.11 | optimizer: 2419.83 | paro-collect: 710.17 | optimizer-compute: 1473.99 | paro-dispatch: 235.50 | paro-row-rsm: 1.03 | paro-col-allred: 1.13 | paro-row-allg: 112.90 | batch-generator: 38.08
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        8/    1000 | consumed samples:           96 | elapsed time per iteration (ms): 4724.8 | total FLOPS: 4.740391e+12 | learning rate: 8.000E-06 | global batch size:    12 | lm loss: 8.916305E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 908.66 | backward-compute: 1377.29 | backward-embedding-all-reduce: 0.11 | optimizer: 2425.91 | paro-collect: 716.93 | optimizer-compute: 1473.54 | paro-dispatch: 235.26 | paro-row-rsm: 1.01 | paro-col-allred: 1.12 | paro-row-allg: 112.76 | batch-generator: 40.31
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration        9/    1000 | consumed samples:          108 | elapsed time per iteration (ms): 4699.6 | total FLOPS: 4.765815e+12 | learning rate: 9.000E-06 | global batch size:    12 | lm loss: 8.860013E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 891.83 | backward-compute: 1375.15 | backward-embedding-all-reduce: 0.11 | optimizer: 2420.54 | paro-collect: 710.42 | optimizer-compute: 1474.74 | paro-dispatch: 235.21 | paro-row-rsm: 1.07 | paro-col-allred: 1.13 | paro-row-allg: 112.99 | batch-generator: 36.13
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       10/    1000 | consumed samples:          120 | elapsed time per iteration (ms): 4699.9 | total FLOPS: 4.765527e+12 | learning rate: 1.000E-05 | global batch size:    12 | lm loss: 8.847581E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 894.58 | backward-compute: 1375.58 | backward-embedding-all-reduce: 0.11 | optimizer: 2416.88 | paro-collect: 707.54 | optimizer-compute: 1473.86 | paro-dispatch: 235.32 | paro-row-rsm: 1.02 | paro-col-allred: 1.13 | paro-row-allg: 112.70 | batch-generator: 36.28
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       11/    1000 | consumed samples:          132 | elapsed time per iteration (ms): 4700.7 | total FLOPS: 4.764741e+12 | learning rate: 1.100E-05 | global batch size:    12 | lm loss: 8.617841E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 895.13 | backward-compute: 1376.93 | backward-embedding-all-reduce: 0.11 | optimizer: 2416.41 | paro-collect: 709.10 | optimizer-compute: 1472.22 | paro-dispatch: 234.92 | paro-row-rsm: 1.07 | paro-col-allred: 1.14 | paro-row-allg: 112.34 | batch-generator: 36.82
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       12/    1000 | consumed samples:          144 | elapsed time per iteration (ms): 4715.5 | total FLOPS: 4.749754e+12 | learning rate: 1.200E-05 | global batch size:    12 | lm loss: 8.552549E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 904.26 | backward-compute: 1379.04 | backward-embedding-all-reduce: 0.11 | optimizer: 2419.70 | paro-collect: 709.26 | optimizer-compute: 1474.57 | paro-dispatch: 235.70 | paro-row-rsm: 1.02 | paro-col-allred: 1.14 | paro-row-allg: 112.89 | batch-generator: 45.97
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       13/    1000 | consumed samples:          156 | elapsed time per iteration (ms): 4706.8 | total FLOPS: 4.758550e+12 | learning rate: 1.300E-05 | global batch size:    12 | lm loss: 8.367023E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 899.08 | backward-compute: 1376.55 | backward-embedding-all-reduce: 0.11 | optimizer: 2419.04 | paro-collect: 708.95 | optimizer-compute: 1474.58 | paro-dispatch: 235.34 | paro-row-rsm: 1.03 | paro-col-allred: 1.14 | paro-row-allg: 112.59 | batch-generator: 40.78
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       14/    1000 | consumed samples:          168 | elapsed time per iteration (ms): 4710.6 | total FLOPS: 4.754754e+12 | learning rate: 1.400E-05 | global batch size:    12 | lm loss: 8.041729E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 902.00 | backward-compute: 1377.22 | backward-embedding-all-reduce: 0.11 | optimizer: 2418.59 | paro-collect: 709.90 | optimizer-compute: 1473.17 | paro-dispatch: 235.35 | paro-row-rsm: 1.02 | paro-col-allred: 1.13 | paro-row-allg: 112.52 | batch-generator: 43.64
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       15/    1000 | consumed samples:          180 | elapsed time per iteration (ms): 4718.6 | total FLOPS: 4.746614e+12 | learning rate: 1.500E-05 | global batch size:    12 | lm loss: 8.113594E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 900.06 | backward-compute: 1378.00 | backward-embedding-all-reduce: 0.11 | optimizer: 2428.32 | paro-collect: 719.57 | optimizer-compute: 1473.32 | paro-dispatch: 235.17 | paro-row-rsm: 1.05 | paro-col-allred: 1.14 | paro-row-allg: 112.77 | batch-generator: 43.59
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       16/    1000 | consumed samples:          192 | elapsed time per iteration (ms): 4719.7 | total FLOPS: 4.745556e+12 | learning rate: 1.600E-05 | global batch size:    12 | lm loss: 8.126138E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 910.42 | backward-compute: 1377.39 | backward-embedding-all-reduce: 0.11 | optimizer: 2418.90 | paro-collect: 710.00 | optimizer-compute: 1473.43 | paro-dispatch: 235.29 | paro-row-rsm: 1.04 | paro-col-allred: 1.25 | paro-row-allg: 112.44 | batch-generator: 44.72
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       17/    1000 | consumed samples:          204 | elapsed time per iteration (ms): 4717.4 | total FLOPS: 4.747823e+12 | learning rate: 1.700E-05 | global batch size:    12 | lm loss: 7.865367E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 903.96 | backward-compute: 1380.41 | backward-embedding-all-reduce: 0.11 | optimizer: 2420.91 | paro-collect: 711.15 | optimizer-compute: 1474.27 | paro-dispatch: 235.32 | paro-row-rsm: 1.02 | paro-col-allred: 1.12 | paro-row-allg: 112.76 | batch-generator: 45.65
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       18/    1000 | consumed samples:          216 | elapsed time per iteration (ms): 4703.2 | total FLOPS: 4.762202e+12 | learning rate: 1.800E-05 | global batch size:    12 | lm loss: 7.914609E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 896.24 | backward-compute: 1376.76 | backward-embedding-all-reduce: 0.11 | optimizer: 2417.37 | paro-collect: 708.70 | optimizer-compute: 1473.67 | paro-dispatch: 234.83 | paro-row-rsm: 1.03 | paro-col-allred: 1.15 | paro-row-allg: 112.54 | batch-generator: 37.93
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       19/    1000 | consumed samples:          228 | elapsed time per iteration (ms): 4707.3 | total FLOPS: 4.758072e+12 | learning rate: 1.900E-05 | global batch size:    12 | lm loss: 7.763173E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 900.75 | backward-compute: 1375.44 | backward-embedding-all-reduce: 0.11 | optimizer: 2418.92 | paro-collect: 710.13 | optimizer-compute: 1473.32 | paro-dispatch: 235.29 | paro-row-rsm: 1.07 | paro-col-allred: 1.14 | paro-row-allg: 112.81 | batch-generator: 45.29
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
vn103559:  iteration       20/    1000 | consumed samples:          240 | elapsed time per iteration (ms): 4708.2 | total FLOPS: 4.757106e+12 | learning rate: 2.000E-05 | global batch size:    12 | lm loss: 7.509524E+00 | loss scale: 1.0 | number of skipped iterations:   0 | number of nan iterations:   0 | allocated memory cur/max: 53.883 48.531 GB |
vn103559: time (ms) | forward-compute: 896.09 | backward-compute: 1380.24 | backward-embedding-all-reduce: 0.11 | optimizer: 2419.29 | paro-collect: 710.16 | optimizer-compute: 1473.75 | paro-dispatch: 235.21 | paro-row-rsm: 1.03 | paro-col-allred: 1.13 | paro-row-allg: 112.51 | batch-generator: 37.81
vn103559: forwarding 0. Mem: 44.903 GB
vn103559: backwarding 0. Mem: 48.531 GB
vn103559: optimizing. Mem: 53.882690891623497 GB
[2879803 ## 2021-08-23/03:13:22] receive request of kill job(bkill).
[2879803 ## mn111: 25088 ## 2021-08-23/03:13:38] job_finished. use-time: 186.141900 (secs)
